{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yaoji\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yaoji\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text2text-generation\", model=\"p208p2002/bart-squad-qg-hl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import sent_tokenize\n",
    "spacy.cli.download(\"en_core_web_md\")\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation(sent):\n",
    "\n",
    "  doc = nlp(sent)\n",
    "  matcher = Matcher(nlp.vocab)\n",
    "\n",
    "  #define the pattern, finds relation through identifying the 'ROOT' tag, which is the central relation.\n",
    "  #Also finds optional preposition terms or agent terms or adjective terms, these are all optional\n",
    "  pattern = [[{'DEP':'ROOT'}, \n",
    "            {'DEP':'prep','OP':\"?\"},\n",
    "            {'DEP':'agent','OP':\"?\"},  \n",
    "            #addd pcomp maybe? google it\n",
    "            {'POS':'ADJ','OP':\"?\"}]]\n",
    "\n",
    "  matcher.add(\"matching_1\", pattern) \n",
    "\n",
    "  matches = matcher(doc)\n",
    "  if matches:\n",
    "        k = len(matches) - 1\n",
    "        span = doc[matches[k][1]:matches[k][2]]\n",
    "        return span.text\n",
    "  else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 500.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['development', 'safe vaccine'], ['quick brown fox', 'lazy dog'], ['SpaCy', 'advanced language processing'], ['amazing film', 'good quality']]\n",
      "delayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# def get_entities(texts):\n",
    "\n",
    "#     entities = []\n",
    "#     for doc in tqdm(nlp.pipe(texts, batch_size=20), total=len(texts)):\n",
    "#         ent1 = ent2 = \"\"\n",
    "#         prv_tok_dep = prv_tok_text = \"\"\n",
    "#         compound_or_modifier = \"\"\n",
    "\n",
    "#         for tok in doc:\n",
    "#             if tok.dep_ == \"punct\":\n",
    "#                 continue  # Skip punctuation tokens\n",
    "\n",
    "#             # Handle compound or modifier tokens\n",
    "#             if tok.dep_ == \"compound\" or tok.dep_.endswith(\"mod\"):\n",
    "#                 compound_or_modifier = f\"{prv_tok_text + ' ' if prv_tok_dep == 'compound' else ''}{tok.text}\"\n",
    "\n",
    "#             # Entity 1: subject\n",
    "#             if \"subj\" in tok.dep_:\n",
    "#                 ent1 = f\"{compound_or_modifier} {tok.text}\".strip()\n",
    "#                 compound_or_modifier = \"\"  # Reset after use\n",
    "\n",
    "#             # Entity 2: object\n",
    "#             if \"obj\" in tok.dep_:\n",
    "#                 ent2 = f\"{compound_or_modifier} {tok.text}\".strip()\n",
    "\n",
    "#             # Update previous token variables\n",
    "#             prv_tok_dep, prv_tok_text = tok.dep_, tok.text\n",
    "\n",
    "#         entities.append([ent1, ent2])\n",
    "\n",
    "#     return entities\n",
    "\n",
    "\n",
    "def get_entities(texts):\n",
    "    entities = []\n",
    "\n",
    "    for doc in tqdm(nlp.pipe(texts, batch_size=20), total=len(texts)):\n",
    "        ent1 = ent2 = \"\"\n",
    "        ent1_complete = ent2_complete = False\n",
    "\n",
    "        for tok in doc:\n",
    "            # Skipping punctuation tokens\n",
    "            if tok.dep_ == \"punct\":\n",
    "                continue\n",
    "\n",
    "            # Capturing the subject entity\n",
    "            if \"subj\" in tok.dep_ and not ent1_complete:\n",
    "                ent1 = tok.text\n",
    "                for ancestor in tok.ancestors:\n",
    "                    if ancestor.dep_ in [\"ROOT\", \"conj\"]:\n",
    "                        # Including modifiers and compounds directly related to the entity\n",
    "                        mods = [child.text for child in tok.lefts if child.dep_ in [\"amod\", \"compound\"]]\n",
    "                        ent1 = \" \".join(mods + [tok.text])\n",
    "                        # Capturing relative clauses introduced by \"that\" or \"which\"\n",
    "                        for child in ancestor.children:\n",
    "                            if child.dep_ in [\"relcl\"] and child.nbor(-1).dep_ == \"nsubj\" and child.nbor(-1).head == tok:\n",
    "                                ent1 += \" \" + \" \".join([child.nbor(-1).text] + [child.text] + [grandchild.text for grandchild in child.children if grandchild.dep_ not in [\"nsubj\"]])\n",
    "                        ent1_complete = True\n",
    "                        break\n",
    "\n",
    "            # Capturing the object entity\n",
    "            if \"obj\" in tok.dep_ and not ent2_complete:\n",
    "                ent2 = tok.text\n",
    "                for ancestor in tok.ancestors:\n",
    "                    if ancestor.dep_ in [\"ROOT\"]:\n",
    "                        mods = [child.text for child in tok.lefts if child.dep_ in [\"amod\", \"compound\"]]\n",
    "                        ent2 = \" \".join(mods + [tok.text])\n",
    "                        # Capturing relative clauses introduced by \"that\" or \"which\"\n",
    "                        for child in ancestor.children:\n",
    "                            if child.dep_ in [\"relcl\"] and child.nbor(-1).dep_ == \"nsubj\" and child.nbor(-1).head == tok:\n",
    "                                ent2 += \" \" + \" \".join([child.nbor(-1).text] + [child.text] + [grandchild.text for grandchild in child.children if grandchild.dep_ not in [\"nsubj\"]])\n",
    "                        ent2_complete = True\n",
    "                        break\n",
    "\n",
    "        entities.append([ent1, ent2])\n",
    "\n",
    "    return entities\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "texts = [\"the development of highly safe vaccine is delayed\", \"The quick brown fox that is happy jumps over the lazy dog .\", \"SpaCy is an open-source software library for advanced natural language processing.\", \"the amazing film that has a good quality is presented had 200 patents\"]\n",
    "entities = get_entities(texts)\n",
    "relations = get_relation(texts[0])\n",
    "print(entities)\n",
    "print(relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split summaries into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>The development of highly immunogenic and safe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>No one type of vaccine will likely fill the gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>MCPyV is a DNA virus with oncogenic potential.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>About 80 of MCC cases are caused by M CPyV inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>China imposed the coronavirus lockdown in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>154</td>\n",
       "      <td>ZIKV has not impacted as many lives as SARS-Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>154</td>\n",
       "      <td>placental and brain infections in fetuses repr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>155</td>\n",
       "      <td>The first Covid-19 listed studies with pediatr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>155</td>\n",
       "      <td>Half of our patients had comorbidities, which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>155</td>\n",
       "      <td>The long-term impact of neurological damage in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic                                           Sentence\n",
       "0       -1  The development of highly immunogenic and safe...\n",
       "1       -1  No one type of vaccine will likely fill the gl...\n",
       "2       -1     MCPyV is a DNA virus with oncogenic potential.\n",
       "3       -1  About 80 of MCC cases are caused by M CPyV inf...\n",
       "4        0  China imposed the coronavirus lockdown in the ...\n",
       "..     ...                                                ...\n",
       "483    154  ZIKV has not impacted as many lives as SARS-Co...\n",
       "484    154  placental and brain infections in fetuses repr...\n",
       "485    155  The first Covid-19 listed studies with pediatr...\n",
       "486    155  Half of our patients had comorbidities, which ...\n",
       "487    155  The long-term impact of neurological damage in...\n",
       "\n",
       "[488 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../abstractive_summaries.csv')\n",
    "\n",
    "sentences = []\n",
    "for index, row in df.iterrows():\n",
    "    topic_sentences = sent_tokenize(row['Abstractive Summary'])\n",
    "    for sentence in topic_sentences:\n",
    "        sentences.append({'Topic': row['Topic'], 'Sentence': sentence})\n",
    "\n",
    "# Creating a new dataframe with topic IDs and individual sentences\n",
    "df_sentences = pd.DataFrame(sentences)\n",
    "\n",
    "# Example to display the first few rows of the new dataframe\n",
    "df_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract entities and relationships from each sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 488/488 [00:00<00:00, 505.03it/s]\n"
     ]
    }
   ],
   "source": [
    "df_sentences['Entities'] = get_entities(df_sentences['Sentence'].tolist())\n",
    "df_sentences['Relation'] = df_sentences['Sentence'].apply(get_relation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tag the extracted info with [HL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_entity_or_relation(sentence, answer):\n",
    "    tagged_sentence = sentence.replace(answer, f\"[HL] {answer} [HL]\")\n",
    "    return tagged_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_data = []\n",
    "for index, row in df_sentences.iterrows():\n",
    "    topic_id = row['Topic']\n",
    "    sentence = row['Sentence']\n",
    "    entities = row['Entities']  # Assuming this is a list of entities\n",
    "    relation = row['Relation']\n",
    "\n",
    "    # Tagging and adding entities\n",
    "    for entity in entities:\n",
    "        if entity:  # Check if entity is not empty\n",
    "            tagged_sentence = tag_entity_or_relation(sentence, entity)\n",
    "            question_data.append({'Topic': topic_id, 'TaggedSentence': tagged_sentence, 'Answer': entity})\n",
    "\n",
    "    # Tagging and adding the relationship, if it exists\n",
    "    if relation:\n",
    "        tagged_sentence = tag_entity_or_relation(sentence, relation)\n",
    "        question_data.append({'Topic': topic_id, 'TaggedSentence': tagged_sentence, 'Answer': relation})\n",
    "\n",
    "# Convert the prepared data into a dataframe\n",
    "df_questions = pd.DataFrame(question_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "def apply_pipe(text):\n",
    "    output = pipe(text)\n",
    "    return output[0]['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate zero shot questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1430 [00:00<?, ?it/s]c:\\Users\\yaoji\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\generation\\utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1430/1430 [08:12<00:00,  2.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>TaggedSentence</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>The [HL] development [HL] of highly immunogeni...</td>\n",
       "      <td>development</td>\n",
       "      <td>What is critical for controlling the COVID-19 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>The development of highly immunogenic and safe...</td>\n",
       "      <td>immunogenic vaccines</td>\n",
       "      <td>The development of highly immunogenic and safe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>The development of highly immunogenic and safe...</td>\n",
       "      <td>be critical</td>\n",
       "      <td>What will the development of highly immunogeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>No one [HL] type [HL] of vaccine will likely f...</td>\n",
       "      <td>type</td>\n",
       "      <td>What type of vaccine will likely fill the glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>No one type of [HL] vaccine [HL] will likely f...</td>\n",
       "      <td>vaccine</td>\n",
       "      <td>What type of vaccine will likely fill the glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>155</td>\n",
       "      <td>Half of our [HL] patients [HL] had comorbiditi...</td>\n",
       "      <td>patients</td>\n",
       "      <td>How many patients had comorbidities?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>155</td>\n",
       "      <td>Half of our patients [HL] had [HL] comorbiditi...</td>\n",
       "      <td>had</td>\n",
       "      <td>Half of our patients had what type of comorbid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>155</td>\n",
       "      <td>The long-[HL] term impact [HL] of neurological...</td>\n",
       "      <td>term impact</td>\n",
       "      <td>What is uncertain about the long term impact o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>155</td>\n",
       "      <td>The long-term impact of [HL] neurological dama...</td>\n",
       "      <td>neurological damage</td>\n",
       "      <td>What is uncertain about the long-term impact o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>155</td>\n",
       "      <td>The long-term impact of neurological damage in...</td>\n",
       "      <td>remains uncertain</td>\n",
       "      <td>The long-term impact of neurological damage in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1430 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic                                     TaggedSentence  \\\n",
       "0        -1  The [HL] development [HL] of highly immunogeni...   \n",
       "1        -1  The development of highly immunogenic and safe...   \n",
       "2        -1  The development of highly immunogenic and safe...   \n",
       "3        -1  No one [HL] type [HL] of vaccine will likely f...   \n",
       "4        -1  No one type of [HL] vaccine [HL] will likely f...   \n",
       "...     ...                                                ...   \n",
       "1425    155  Half of our [HL] patients [HL] had comorbiditi...   \n",
       "1426    155  Half of our patients [HL] had [HL] comorbiditi...   \n",
       "1427    155  The long-[HL] term impact [HL] of neurological...   \n",
       "1428    155  The long-term impact of [HL] neurological dama...   \n",
       "1429    155  The long-term impact of neurological damage in...   \n",
       "\n",
       "                    Answer                                           Question  \n",
       "0              development  What is critical for controlling the COVID-19 ...  \n",
       "1     immunogenic vaccines  The development of highly immunogenic and safe...  \n",
       "2              be critical  What will the development of highly immunogeni...  \n",
       "3                     type  What type of vaccine will likely fill the glob...  \n",
       "4                  vaccine  What type of vaccine will likely fill the glob...  \n",
       "...                    ...                                                ...  \n",
       "1425              patients               How many patients had comorbidities?  \n",
       "1426                   had  Half of our patients had what type of comorbid...  \n",
       "1427           term impact  What is uncertain about the long term impact o...  \n",
       "1428   neurological damage  What is uncertain about the long-term impact o...  \n",
       "1429     remains uncertain  The long-term impact of neurological damage in...  \n",
       "\n",
       "[1430 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions['Question'] = df_questions['TaggedSentence'].progress_apply(apply_pipe)\n",
    "df_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions.to_csv('../question_answer_pair_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
